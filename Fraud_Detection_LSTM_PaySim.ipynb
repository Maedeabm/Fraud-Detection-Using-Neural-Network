{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXGFuFadq/1PxGyGxFYYW0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maedeabm/Fraud-Detection-Using-Neural-Network/blob/main/Fraud_Detection_LSTM_PaySim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the nature of the PaySim dataset (sequential and imbalanced) and the current advances in time series processing, I'd suggest using LSTM (Long Short-Term Memory) networks. They are designed to work with sequence data and can capture long-term dependencies which are crucial for such datasets.\n",
        "\n",
        "Let's start with a basic implementation of an LSTM using TensorFlow and Keras in a Google Colab environment."
      ],
      "metadata": {
        "id": "DC_Pa8h7LrvO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Setting Up Google Colab:\n",
        "\n",
        "Open Google Colab and start a new notebook. Use the following initial setup:"
      ],
      "metadata": {
        "id": "nCGe_pPKE8KV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcAlzuz6_dEw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3fbf52f-91b3-480f-e528-2e7678d75af4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.14)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Load the PaySim Dataset:\n",
        "\n",
        "PaySim:\n",
        "\n",
        "  Description: PaySim simulates mobile money transactions based on a sample of real transactions extracted from one month of financial logs from a mobile money service implemented in an African country.\n",
        "    \n",
        "  Features: Step (time), type, amount, name of origin, old balance of origin, new balance of origin, name of destination, old balance of destination, new balance of destination, fraud (binary).\n",
        "  \n",
        "  Link: PaySim on Kaggle\n",
        "\n",
        "First, upload the dataset to Colab:"
      ],
      "metadata": {
        "id": "evd6x_DJE_xE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can access the PaySim dataset directly from Kaggle using their API. Here's how you can do that on Google Colab:\n",
        "1. Setting Up Kaggle in Google Colab:\n",
        "\n",
        "1.1 If you don’t have the Kaggle API token, you need to create it:\n",
        "\n",
        "  Go to your Kaggle account settings.\n",
        "    \n",
        "  Click on 'Create New API Token'.\n",
        "  \n",
        "  This will download a file named kaggle.json.\n",
        "\n",
        "1.2 Upload this to Google Colab:"
      ],
      "metadata": {
        "id": "veedamogGts-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Assuming the dataset is named \"paysim.csv\"\n",
        "data = pd.read_csv('paysim.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "64vtnEsMIEkh",
        "outputId": "3b514380-b709-41d5-8cda-0031cb8af79f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1ce3351e-b937-4fa4-ba42-466643683c30\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1ce3351e-b937-4fa4-ba42-466643683c30\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving paysim.csv to paysim.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Data Preprocessing:\n",
        "\n",
        "This will be a basic preprocessing to get started:"
      ],
      "metadata": {
        "id": "b05Gw82Ij3uX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping columns that may not be required for this basic model\n",
        "data = data.drop(['nameOrig', 'nameDest', 'isFlaggedFraud'], axis=1)\n",
        "\n",
        "# Convert categorical columns to numerical values\n",
        "data = pd.get_dummies(data, columns=['type'], drop_first=True)\n",
        "\n",
        "# Normalize the features\n",
        "scaler = MinMaxScaler()\n",
        "data[['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']] = scaler.fit_transform(data[['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']])\n",
        "\n",
        "# Splitting data into features and target variable\n",
        "X = data.drop('isFraud', axis=1).values\n",
        "y = data['isFraud'].values\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape input to be 3D for LSTM [samples, timesteps, features]\n",
        "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n"
      ],
      "metadata": {
        "id": "WDNd4rPZj5Pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Define and Train the LSTM Model:"
      ],
      "metadata": {
        "id": "wOdkv2dhkFti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Implementing early stopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2, verbose=2, callbacks=[es])\n"
      ],
      "metadata": {
        "id": "W9Gs3gbqkGXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8a05d30-08c3-445e-947f-e30efd555e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "63627/63627 - 261s - loss: 0.0096 - accuracy: 0.9987 - val_loss: 0.0104 - val_accuracy: 0.9987 - 261s/epoch - 4ms/step\n",
            "Epoch 2/100\n",
            "63627/63627 - 252s - loss: 0.0091 - accuracy: 0.9987 - val_loss: 0.0082 - val_accuracy: 0.9987 - 252s/epoch - 4ms/step\n",
            "Epoch 3/100\n",
            "63627/63627 - 253s - loss: 0.0089 - accuracy: 0.9987 - val_loss: 0.0081 - val_accuracy: 0.9987 - 253s/epoch - 4ms/step\n",
            "Epoch 4/100\n",
            "63627/63627 - 237s - loss: 0.0088 - accuracy: 0.9987 - val_loss: 0.0082 - val_accuracy: 0.9987 - 237s/epoch - 4ms/step\n",
            "Epoch 5/100\n",
            "63627/63627 - 252s - loss: 0.0086 - accuracy: 0.9987 - val_loss: 0.0077 - val_accuracy: 0.9987 - 252s/epoch - 4ms/step\n",
            "Epoch 6/100\n",
            "63627/63627 - 251s - loss: 0.0085 - accuracy: 0.9987 - val_loss: 0.0077 - val_accuracy: 0.9987 - 251s/epoch - 4ms/step\n",
            "Epoch 7/100\n",
            "63627/63627 - 235s - loss: 0.0084 - accuracy: 0.9987 - val_loss: 0.0075 - val_accuracy: 0.9987 - 235s/epoch - 4ms/step\n",
            "Epoch 8/100\n",
            "63627/63627 - 249s - loss: 0.0082 - accuracy: 0.9987 - val_loss: 0.0078 - val_accuracy: 0.9987 - 249s/epoch - 4ms/step\n",
            "Epoch 9/100\n",
            "63627/63627 - 234s - loss: 0.0081 - accuracy: 0.9987 - val_loss: 0.0073 - val_accuracy: 0.9987 - 234s/epoch - 4ms/step\n",
            "Epoch 10/100\n",
            "63627/63627 - 238s - loss: 0.0079 - accuracy: 0.9987 - val_loss: 0.0067 - val_accuracy: 0.9987 - 238s/epoch - 4ms/step\n",
            "Epoch 11/100\n",
            "63627/63627 - 237s - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.0067 - val_accuracy: 0.9987 - 237s/epoch - 4ms/step\n",
            "Epoch 12/100\n",
            "63627/63627 - 237s - loss: 0.0077 - accuracy: 0.9987 - val_loss: 0.0074 - val_accuracy: 0.9987 - 237s/epoch - 4ms/step\n",
            "Epoch 13/100\n",
            "63627/63627 - 237s - loss: 0.0076 - accuracy: 0.9987 - val_loss: 0.0068 - val_accuracy: 0.9987 - 237s/epoch - 4ms/step\n",
            "Epoch 14/100\n",
            "63627/63627 - 250s - loss: 0.0075 - accuracy: 0.9987 - val_loss: 0.0068 - val_accuracy: 0.9988 - 250s/epoch - 4ms/step\n",
            "Epoch 15/100\n",
            "63627/63627 - 250s - loss: 0.0074 - accuracy: 0.9987 - val_loss: 0.0067 - val_accuracy: 0.9988 - 250s/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "63627/63627 - 235s - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.0061 - val_accuracy: 0.9988 - 235s/epoch - 4ms/step\n",
            "Epoch 17/100\n",
            "63627/63627 - 235s - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.0063 - val_accuracy: 0.9988 - 235s/epoch - 4ms/step\n",
            "Epoch 18/100\n",
            "63627/63627 - 236s - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.0064 - val_accuracy: 0.9988 - 236s/epoch - 4ms/step\n",
            "Epoch 19/100\n",
            "63627/63627 - 240s - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.0059 - val_accuracy: 0.9988 - 240s/epoch - 4ms/step\n",
            "Epoch 20/100\n",
            "63627/63627 - 253s - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.0058 - val_accuracy: 0.9988 - 253s/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "63627/63627 - 253s - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.0057 - val_accuracy: 0.9988 - 253s/epoch - 4ms/step\n",
            "Epoch 22/100\n",
            "63627/63627 - 236s - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.0057 - val_accuracy: 0.9988 - 236s/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "63627/63627 - 249s - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.0056 - val_accuracy: 0.9990 - 249s/epoch - 4ms/step\n",
            "Epoch 24/100\n",
            "63627/63627 - 234s - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.0053 - val_accuracy: 0.9988 - 234s/epoch - 4ms/step\n",
            "Epoch 25/100\n",
            "63627/63627 - 235s - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.0061 - val_accuracy: 0.9989 - 235s/epoch - 4ms/step\n",
            "Epoch 26/100\n",
            "63627/63627 - 235s - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.0063 - val_accuracy: 0.9988 - 235s/epoch - 4ms/step\n",
            "Epoch 27/100\n",
            "63627/63627 - 234s - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.0059 - val_accuracy: 0.9988 - 234s/epoch - 4ms/step\n",
            "Epoch 28/100\n",
            "63627/63627 - 250s - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.0057 - val_accuracy: 0.9988 - 250s/epoch - 4ms/step\n",
            "Epoch 29/100\n",
            "63627/63627 - 250s - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.0061 - val_accuracy: 0.9988 - 250s/epoch - 4ms/step\n",
            "Epoch 30/100\n",
            "63627/63627 - 236s - loss: 0.0063 - accuracy: 0.9989 - val_loss: 0.0051 - val_accuracy: 0.9989 - 236s/epoch - 4ms/step\n",
            "Epoch 31/100\n",
            "63627/63627 - 249s - loss: 0.0063 - accuracy: 0.9989 - val_loss: 0.0052 - val_accuracy: 0.9989 - 249s/epoch - 4ms/step\n",
            "Epoch 32/100\n",
            "63627/63627 - 236s - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.0050 - val_accuracy: 0.9990 - 236s/epoch - 4ms/step\n",
            "Epoch 33/100\n",
            "63627/63627 - 254s - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.0053 - val_accuracy: 0.9989 - 254s/epoch - 4ms/step\n",
            "Epoch 34/100\n",
            "63627/63627 - 262s - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.0052 - val_accuracy: 0.9989 - 262s/epoch - 4ms/step\n",
            "Epoch 35/100\n",
            "63627/63627 - 264s - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.0056 - val_accuracy: 0.9989 - 264s/epoch - 4ms/step\n",
            "Epoch 36/100\n",
            "63627/63627 - 250s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.0047 - val_accuracy: 0.9989 - 250s/epoch - 4ms/step\n",
            "Epoch 37/100\n",
            "63627/63627 - 249s - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.0053 - val_accuracy: 0.9989 - 249s/epoch - 4ms/step\n",
            "Epoch 38/100\n",
            "63627/63627 - 267s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.0048 - val_accuracy: 0.9989 - 267s/epoch - 4ms/step\n",
            "Epoch 39/100\n",
            "63627/63627 - 270s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.0057 - val_accuracy: 0.9990 - 270s/epoch - 4ms/step\n",
            "Epoch 40/100\n",
            "63627/63627 - 263s - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.0051 - val_accuracy: 0.9991 - 263s/epoch - 4ms/step\n",
            "Epoch 41/100\n",
            "63627/63627 - 249s - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.0045 - val_accuracy: 0.9991 - 249s/epoch - 4ms/step\n",
            "Epoch 42/100\n",
            "63627/63627 - 252s - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.0049 - val_accuracy: 0.9990 - 252s/epoch - 4ms/step\n",
            "Epoch 43/100\n",
            "63627/63627 - 250s - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0044 - val_accuracy: 0.9991 - 250s/epoch - 4ms/step\n",
            "Epoch 44/100\n",
            "63627/63627 - 249s - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0046 - val_accuracy: 0.9990 - 249s/epoch - 4ms/step\n",
            "Epoch 45/100\n",
            "63627/63627 - 245s - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0047 - val_accuracy: 0.9988 - 245s/epoch - 4ms/step\n",
            "Epoch 46/100\n",
            "63627/63627 - 249s - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0051 - val_accuracy: 0.9990 - 249s/epoch - 4ms/step\n",
            "Epoch 47/100\n",
            "63627/63627 - 234s - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0056 - val_accuracy: 0.9989 - 234s/epoch - 4ms/step\n",
            "Epoch 48/100\n",
            "63627/63627 - 235s - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0052 - val_accuracy: 0.9991 - 235s/epoch - 4ms/step\n",
            "Epoch 49/100\n",
            "63627/63627 - 235s - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0047 - val_accuracy: 0.9991 - 235s/epoch - 4ms/step\n",
            "Epoch 50/100\n",
            "63627/63627 - 248s - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0056 - val_accuracy: 0.9990 - 248s/epoch - 4ms/step\n",
            "Epoch 51/100\n",
            "63627/63627 - 234s - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0059 - val_accuracy: 0.9990 - 234s/epoch - 4ms/step\n",
            "Epoch 52/100\n",
            "63627/63627 - 249s - loss: 0.0055 - accuracy: 0.9990 - val_loss: 0.0051 - val_accuracy: 0.9990 - 249s/epoch - 4ms/step\n",
            "Epoch 53/100\n",
            "63627/63627 - 248s - loss: 0.0055 - accuracy: 0.9990 - val_loss: 0.0051 - val_accuracy: 0.9990 - 248s/epoch - 4ms/step\n",
            "Epoch 53: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Model Evaluation:"
      ],
      "metadata": {
        "id": "GJfA94O6j230"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob = model.predict(X_test)\n",
        "y_pred = (y_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "id": "3cwT8tqXkYhA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5863a984-2f93-4a64-f43d-c5d1dad9041d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39767/39767 [==============================] - 65s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00   1270904\n",
            "           1       0.99      0.22      0.35      1620\n",
            "\n",
            "    accuracy                           1.00   1272524\n",
            "   macro avg       1.00      0.61      0.68   1272524\n",
            "weighted avg       1.00      1.00      1.00   1272524\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result you provided is a classification report, commonly used for evaluating the performance of a classification model. Let's break down what the metrics suggest:\n",
        "\n",
        "  Class 0 (Not Fraudulent Transactions):\n",
        "        Precision: The model is 100% precise when it predicts a transaction as non-fraudulent, which means every time it said a transaction was legit, it was right.\n",
        "        Recall: The model is also capturing 100% of the non-fraudulent transactions.\n",
        "\n",
        "  Class 1 (Fraudulent Transactions):\n",
        "        Precision: The precision is 99%, meaning that when the model predicts a transaction is fraudulent, it's correct 99% of the time.\n",
        "        Recall: The recall is 22%. This means that the model only captures 22% of all the actual fraudulent transactions. This is concerning because 78% of fraudulent transactions are going undetected.\n",
        "        F1-score: This is a harmonic mean of precision and recall. Given that the recall is low, the F1-score for the fraudulent class is also quite low at 35%.\n",
        "\n",
        "  Accuracy: While the overall accuracy is 100%, accuracy can be misleading in imbalanced datasets (like this one, where fraudulent transactions are much fewer). A model could predict every transaction as non-fraudulent and still achieve a very high accuracy due to the class imbalance.\n",
        "\n",
        "  Macro Avg: This averages the unweighted mean per label. The average precision and recall are both high, but the F1-score (which considers both) is relatively low due to the low recall for the fraudulent class.\n",
        "\n",
        "  Weighted Avg: This averages the support-weighted mean per label. These numbers are very high because the vast majority of the dataset consists of the non-fraudulent class.\n",
        "\n",
        "Is it a good result?\n",
        "While the results for the non-fraudulent class are excellent, the primary concern is the low recall for the fraudulent class. In the context of fraud detection, false negatives (fraudulent transactions that the model fails to detect) can be very costly. Even if the model is precise in its predictions of fraud, it's missing a significant portion of them.\n",
        "\n",
        "To improve this, you might want to:\n",
        "\n",
        "  Address the class imbalance further, possibly with techniques like SMOTE or ADASYN.\n",
        "  \n",
        "  Experiment with different models or architectures.\n",
        "  \n",
        "  Fine-tune the model, focusing on improving recall for the fraudulent class, possibly by adjusting the decision threshold.\n",
        "  \n",
        "  Consider ensemble methods or more advanced techniques.\n",
        "\n",
        "In fraud detection, maximizing recall for the fraudulent class (while keeping precision reasonably high) is often a primary objective."
      ],
      "metadata": {
        "id": "v-_Nr7FlJthR"
      }
    }
  ]
}